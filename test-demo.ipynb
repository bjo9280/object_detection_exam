{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:48:58.948403Z",
     "start_time": "2018-08-22T01:48:58.932809Z"
    }
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "from __future__ import print_function,division,absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:48:59.573452Z",
     "start_time": "2018-08-22T01:48:58.948403Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:48:59.589085Z",
     "start_time": "2018-08-22T01:48:59.573452Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# sys.path.insert(0,os.path.realpath(\"../slim\"))\n",
    "# sys.path.insert(0,os.path.realpath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:48:59.604703Z",
     "start_time": "2018-08-22T01:48:59.589085Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:01.964260Z",
     "start_time": "2018-08-22T01:48:59.604703Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "assert tf.__version__ >= '1.4.0', \\\n",
    "    ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')\n",
    "\n",
    "tag_constants = tf.saved_model.tag_constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:01.995511Z",
     "start_time": "2018-08-22T01:49:01.979885Z"
    }
   },
   "outputs": [],
   "source": [
    "export_dir = 'export/saved_model' # 'export/Servo/1533281229'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:02.011137Z",
     "start_time": "2018-08-22T01:49:01.995511Z"
    }
   },
   "outputs": [],
   "source": [
    "saved_model_dir = export_dir\n",
    "tag_set = tag_constants.SERVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:03.026869Z",
     "start_time": "2018-08-22T01:49:02.011137Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import saved_model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:06.886507Z",
     "start_time": "2018-08-22T01:49:03.026869Z"
    }
   },
   "outputs": [],
   "source": [
    "meta_graph_def = saved_model_utils.get_meta_graph_def(saved_model_dir,tag_set)\n",
    "signature_def = meta_graph_def.signature_def['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:06.917759Z",
     "start_time": "2018-08-22T01:49:06.886507Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': 'image_tensor:0'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_map = {k: input_.name for k,input_ in signature_def.inputs.items()}\n",
    "inputs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:06.933413Z",
     "start_time": "2018-08-22T01:49:06.917759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detection_boxes': 'detection_boxes:0',\n",
       " 'detection_classes': 'detection_classes:0',\n",
       " 'detection_scores': 'detection_scores:0',\n",
       " 'num_detections': 'num_detections:0'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_map = {k: output_.name for k,output_ in signature_def.outputs.items()}\n",
    "outputs_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:06.949012Z",
     "start_time": "2018-08-22T01:49:06.933413Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = './datasetname_label_map.pbtxt'\n",
    "NUM_CLASSES = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:06.980292Z",
     "start_time": "2018-08-22T01:49:06.949012Z"
    }
   },
   "outputs": [],
   "source": [
    "# from object_detection.utils import label_map_util\n",
    "import label_map_util\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map,\n",
    "    max_num_classes=NUM_CLASSES,\n",
    "    use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:06.995920Z",
     "start_time": "2018-08-22T01:49:06.980292Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:07.011545Z",
     "start_time": "2018-08-22T01:49:06.995920Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "# TEST_IMAGE_PATHS = glob.glob('images/*.jpg')\n",
    "TEST_IMAGE_PATHS = sorted(glob.glob('Test_ImageSet_datasetname/Val_tf/*'))\n",
    "#TEST_IMAGE_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:07.027143Z",
     "start_time": "2018-08-22T01:49:07.011545Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def image_cache_path(filepath):\n",
    "    filepath_base, _ = os.path.splitext(filepath)\n",
    "    dir_, base_ = os.path.split(filepath_base)\n",
    "    dirbase_ = os.path.basename(dir_)\n",
    "    cache_path = 'cache/' + dirbase_ + '__' + base_ + '.png'\n",
    "    return cache_path\n",
    "    \n",
    "if not os.path.isdir('cache'):\n",
    "    os.makedirs('cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:07.042769Z",
     "start_time": "2018-08-22T01:49:07.027143Z"
    }
   },
   "outputs": [],
   "source": [
    "# tensorflow setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:25.512892Z",
     "start_time": "2018-08-22T01:49:07.042769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto(gpu_options={'allow_growth':True})\n",
    "sess = tf.Session(config=config)\n",
    "tf.saved_model.loader.load(sess, [tag_constants.SERVING], export_dir);\n",
    "image_tensor_ = tf.get_default_graph().get_tensor_by_name(inputs_map['inputs'])\n",
    "tensor_dict = {k: tf.get_default_graph().get_tensor_by_name(v) for k, v in outputs_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:25.528486Z",
     "start_time": "2018-08-22T01:49:25.512892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'image_tensor:0' shape=(?, ?, ?, 3) dtype=uint8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:50:00.202786Z",
     "start_time": "2018-08-22T01:49:25.528486Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dry-run\n",
    "image_path = TEST_IMAGE_PATHS[0]\n",
    "image_np = load_image_into_numpy_array(Image.open(image_path))\n",
    "image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "output_dict = sess.run(tensor_dict,feed_dict={image_tensor_: image_np_expanded})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import visualization_utils as vis_util\n",
    "\n",
    "\n",
    "im_names = TEST_IMAGE_PATHS\n",
    "\n",
    "\n",
    "t_start = time.time()\n",
    "t_inference_elapsed_sum = 0.0\n",
    "for image_path in im_names:\n",
    "    # the array based representation of the image will be used later in order to prepare the\n",
    "    # result image with boxes and labels on it.\n",
    "    #image_np = load_image_into_numpy_array(Image.open(image_path))\n",
    "    image_np = cv2.imread(image_path, flags=cv2.IMREAD_COLOR )\n",
    "    image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    # Run inference\n",
    "    t_inference_start = time.time()\n",
    "    output_dict = sess.run(tensor_dict,feed_dict={image_tensor_: image_np_expanded})\n",
    "    t_inference_elapsed = (time.time() - t_inference_start)\n",
    "    t_inference_elapsed_sum += t_inference_elapsed\n",
    "    \n",
    "    # textual report\n",
    "    detection_boxes = output_dict['detection_boxes'][0]\n",
    "    detection_classes = output_dict['detection_classes'][0].astype(int)\n",
    "    detection_scores = output_dict['detection_scores'][0]\n",
    "    \n",
    "    detection_masks = None\n",
    "    if output_dict.get('detection_masks'):\n",
    "        detection_masks, _ = output_dict.get('detection_masks')\n",
    "    \n",
    "    print('Image:',image_path,'t_inference_elapsed:',t_inference_elapsed)\n",
    "\n",
    "    image_size = image_np.shape[:2] * 2\n",
    "\n",
    "    true_boxes_index = np.where(detection_scores > 0.5)[0]\n",
    "    for i, box in enumerate(detection_boxes[true_boxes_index]):\n",
    "        print('  Box:',i,'class:',category_index[detection_classes[i]]['name'],\n",
    "              'score:',detection_scores[i],'box:',(box * image_size).astype(int))\n",
    "\n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        detection_boxes,\n",
    "        detection_classes,\n",
    "        detection_scores,\n",
    "        category_index,\n",
    "        instance_masks=detection_masks, # output_dict.get('detection_masks'),\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(image_np)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(image_cache_path(image_path))\n",
    "    plt.close()\n",
    "t_elapsed = time.time() - t_start\n",
    "t_elapsed /= len(im_names)\n",
    "t_inference_elapsed_sum /= len(im_names)\n",
    "print(('mean t_elapsed',t_elapsed,'mean t_inference_elapsed',t_inference_elapsed_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback import print_exc\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "\n",
    "def find_groundtruth(filepath):\n",
    "    filepath_base, _ = os.path.splitext(filepath)\n",
    "    dir_, base_ = os.path.split(filepath_base)\n",
    "    try:\n",
    "        gt_image_path = glob.glob('Test_ImageSet_datasetname/Val_tf/' + base_ + '.*')[0]\n",
    "        gt_anno_path  = glob.glob('annotations/xmls/Val/' + base_ + '.xml')[0]\n",
    "        return gt_image_path, gt_anno_path\n",
    "    except:\n",
    "        print(('gt not found for',filepath),file=sys.stderr)\n",
    "        return None, None\n",
    "\n",
    "class AnnotationNode:\n",
    "    def update(self,**kwargs):\n",
    "        vars(self).update(dict(**kwargs))\n",
    "    def __repr__(self):\n",
    "        return str(vars(self))\n",
    "\n",
    "def parse_annotation(filename,image_dir=None,check_image=False):\n",
    "    anno_ = ET.parse(filename).getroot()\n",
    "    image_filename = anno_.findtext('image_filename')\n",
    "    image_path = anno_.findtext('path')\n",
    "\n",
    "    if image_dir is not None:\n",
    "        dir_, file_ = os.path.split(image_path)\n",
    "        image_path = os.path.join(image_dir,file_)\n",
    "\n",
    "    if check_image:\n",
    "        try:\n",
    "            img = Image.open(image_path)\n",
    "            del img\n",
    "        except:\n",
    "            print(('parse_annotation','image load failed',filename,image_path),file=sys.stderr)\n",
    "            return None\n",
    "\n",
    "    segmented = int(anno_.findtext('segmented'))\n",
    "    objects = []\n",
    "    for obj_ in anno_.findall('object'):\n",
    "        obj_name = obj_.findtext('name')\n",
    "        obj_pose = obj_.findtext('pose')\n",
    "        obj_truncated = int(obj_.findtext('truncated'))\n",
    "        obj_difficult = int(obj_.findtext('difficult'))\n",
    "        obj_bndbox = [[\n",
    "            int(obj_.find('bndbox').findtext('xmin')),\n",
    "            int(obj_.find('bndbox').findtext('ymin')),\n",
    "        ],[\n",
    "            int(obj_.find('bndbox').findtext('xmax')),\n",
    "            int(obj_.find('bndbox').findtext('ymax')),\n",
    "        ]]\n",
    "        obj = AnnotationNode()\n",
    "        obj.update(\n",
    "            name=obj_name,\n",
    "            pose=obj_pose,\n",
    "            truncated=obj_truncated,\n",
    "            difficult=obj_difficult,\n",
    "            bndbox=obj_bndbox,\n",
    "        )\n",
    "        objects.append(obj)\n",
    "    anno = AnnotationNode()\n",
    "    anno.update(\n",
    "        anno_path=filename,\n",
    "        image_path=image_path,\n",
    "        segmented=segmented,\n",
    "        objects=objects,\n",
    "    )\n",
    "    return anno\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def show_annotation(anno_,image_=None,ax=None):\n",
    "    if image_ is None:\n",
    "        image_ = anno_.image_path\n",
    "\n",
    "    try:\n",
    "        img = Image.open(image_)\n",
    "    except:\n",
    "        print_exc()\n",
    "        print('*** Image read error:',image_,file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        _, ax_ = plt.subplots(1,figsize=(11,11))\n",
    "    else:\n",
    "        ax_ = ax\n",
    "\n",
    "    ax_.imshow(img)\n",
    "\n",
    "    for obj in anno_.objects:\n",
    "        min_, max_ = obj.bndbox\n",
    "        minx, miny = min_\n",
    "        maxx, maxy = max_\n",
    "        ax_.add_patch(plt.Rectangle(min_,maxx-minx,maxy-miny,fill=False,color='r',lw=3))\n",
    "        ax_.text(minx, miny - 15, obj.name,color='r',fontsize=12,bbox=dict(facecolor='blue',alpha=0.5))\n",
    "    ax_.set_title('{:s}, {:d} objs'.format(os.path.basename(anno_.image_path),len(anno_.objects)))\n",
    "    if ax is None:\n",
    "        plt.tight_layout()\n",
    "        plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c7bed96f3444b30a3018aed32ed8d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='num', max=78), Output()), _dom_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact,IntSlider\n",
    "# from IPython.display import Image\n",
    "\n",
    "@interact(num=IntSlider(0,0,len(im_names)-1,continuous_update=False))\n",
    "def show_result(num):\n",
    "    im_name = im_names[num]\n",
    "    gt_image_path, gt_anno_path = find_groundtruth(im_name)\n",
    "    if gt_image_path is not None:\n",
    "        plt.figure(figsize=(11,6))\n",
    "        ax = plt.subplot(121)\n",
    "        result_image_path = image_cache_path(im_name)\n",
    "        ax.imshow(Image.open(result_image_path))\n",
    "        ax.set_title(result_image_path)\n",
    "        ax.set_axis_off()\n",
    "        ax = plt.subplot(122)\n",
    "        anno = parse_annotation(gt_anno_path)\n",
    "        show_annotation(anno, gt_image_path, ax=ax)\n",
    "        ax.set_axis_off()\n",
    "        plt.tight_layout()\n",
    "        plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
