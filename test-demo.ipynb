{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:48:58.948403Z",
     "start_time": "2018-08-22T01:48:58.932809Z"
    }
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "from __future__ import print_function,division,absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:48:59.573452Z",
     "start_time": "2018-08-22T01:48:58.948403Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:48:59.589085Z",
     "start_time": "2018-08-22T01:48:59.573452Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# sys.path.insert(0,os.path.realpath(\"../slim\"))\n",
    "# sys.path.insert(0,os.path.realpath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:48:59.604703Z",
     "start_time": "2018-08-22T01:48:59.589085Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:01.964260Z",
     "start_time": "2018-08-22T01:48:59.604703Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "assert tf.__version__ >= '1.4.0', \\\n",
    "    ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')\n",
    "\n",
    "tag_constants = tf.saved_model.tag_constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:01.995511Z",
     "start_time": "2018-08-22T01:49:01.979885Z"
    }
   },
   "outputs": [],
   "source": [
    "export_dir = 'export/saved_model' # 'export/Servo/1533281229'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:02.011137Z",
     "start_time": "2018-08-22T01:49:01.995511Z"
    }
   },
   "outputs": [],
   "source": [
    "saved_model_dir = export_dir\n",
    "tag_set = tag_constants.SERVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:03.026869Z",
     "start_time": "2018-08-22T01:49:02.011137Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import saved_model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:06.886507Z",
     "start_time": "2018-08-22T01:49:03.026869Z"
    }
   },
   "outputs": [],
   "source": [
    "meta_graph_def = saved_model_utils.get_meta_graph_def(saved_model_dir,tag_set)\n",
    "signature_def = meta_graph_def.signature_def['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:06.917759Z",
     "start_time": "2018-08-22T01:49:06.886507Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': 'image_tensor:0'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_map = {k: input_.name for k,input_ in signature_def.inputs.items()}\n",
    "inputs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:06.933413Z",
     "start_time": "2018-08-22T01:49:06.917759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detection_boxes': 'detection_boxes:0',\n",
       " 'detection_classes': 'detection_classes:0',\n",
       " 'detection_scores': 'detection_scores:0',\n",
       " 'num_detections': 'num_detections:0'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_map = {k: output_.name for k,output_ in signature_def.outputs.items()}\n",
    "outputs_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:06.949012Z",
     "start_time": "2018-08-22T01:49:06.933413Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = './datasetname_label_map.pbtxt'\n",
    "NUM_CLASSES = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:06.980292Z",
     "start_time": "2018-08-22T01:49:06.949012Z"
    }
   },
   "outputs": [],
   "source": [
    "# from object_detection.utils import label_map_util\n",
    "import label_map_util\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map,\n",
    "    max_num_classes=NUM_CLASSES,\n",
    "    use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:06.995920Z",
     "start_time": "2018-08-22T01:49:06.980292Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:07.011545Z",
     "start_time": "2018-08-22T01:49:06.995920Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "# TEST_IMAGE_PATHS = glob.glob('images/*.jpg')\n",
    "TEST_IMAGE_PATHS = sorted(glob.glob('Test_ImageSet_datasetname/Val_tf/*'))\n",
    "#TEST_IMAGE_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:07.027143Z",
     "start_time": "2018-08-22T01:49:07.011545Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def image_cache_path(filepath):\n",
    "    filepath_base, _ = os.path.splitext(filepath)\n",
    "    dir_, base_ = os.path.split(filepath_base)\n",
    "    dirbase_ = os.path.basename(dir_)\n",
    "    cache_path = 'cache/' + dirbase_ + '__' + base_ + '.png'\n",
    "    return cache_path\n",
    "    \n",
    "if not os.path.isdir('cache'):\n",
    "    os.makedirs('cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:07.042769Z",
     "start_time": "2018-08-22T01:49:07.027143Z"
    }
   },
   "outputs": [],
   "source": [
    "# tensorflow setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:25.512892Z",
     "start_time": "2018-08-22T01:49:07.042769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto(gpu_options={'allow_growth':True})\n",
    "sess = tf.Session(config=config)\n",
    "tf.saved_model.loader.load(sess, [tag_constants.SERVING], export_dir);\n",
    "image_tensor_ = tf.get_default_graph().get_tensor_by_name(inputs_map['inputs'])\n",
    "tensor_dict = {k: tf.get_default_graph().get_tensor_by_name(v) for k, v in outputs_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:49:25.528486Z",
     "start_time": "2018-08-22T01:49:25.512892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'image_tensor:0' shape=(?, ?, ?, 3) dtype=uint8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T01:50:00.202786Z",
     "start_time": "2018-08-22T01:49:25.528486Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dry-run\n",
    "image_path = TEST_IMAGE_PATHS[0]\n",
    "image_np = load_image_into_numpy_array(Image.open(image_path))\n",
    "image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "output_dict = sess.run(tensor_dict,feed_dict={image_tensor_: image_np_expanded})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: Test_ImageSet_datasetname/Val_tf/1.png t_inference_elapsed: 0.2299199104309082\n",
      "  Box: 0 class: turn_right score: 0.89095473 box: [ 395 1213  498 1321]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/10.png t_inference_elapsed: 0.22524666786193848\n",
      "  Box: 0 class: go_straight score: 0.96747535 box: [ 73 169 156 250]\n",
      "  Box: 1 class: turn_right score: 0.96560985 box: [ 256 1279  385 1403]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/11.png t_inference_elapsed: 0.2056283950805664\n",
      "  Box: 0 class: turn_right_1to2 score: 0.9964594 box: [ 23 863 100 921]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/2.png t_inference_elapsed: 0.2189936637878418\n",
      "  Box: 0 class: go_straight score: 0.74454 box: [121 236 189 305]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_095543.png t_inference_elapsed: 0.22465085983276367\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_095623.png t_inference_elapsed: 0.2267765998840332\n",
      "  Box: 0 class: turn_right score: 0.98333573 box: [ 290 1366  428 1499]\n",
      "  Box: 1 class: go_straight score: 0.67576367 box: [275 263 358 343]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_095642.png t_inference_elapsed: 0.22254538536071777\n",
      "  Box: 0 class: turn_left score: 0.8710691 box: [ 285 1390  407 1531]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_095652.png t_inference_elapsed: 0.22617363929748535\n",
      "  Box: 0 class: go_straight score: 0.9765661 box: [202 575 285 661]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_095701.png t_inference_elapsed: 0.24862933158874512\n",
      "  Box: 0 class: turn_right score: 0.9971444 box: [ 160 1484  316 1641]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_095705.png t_inference_elapsed: 0.23331403732299805\n",
      "  Box: 0 class: turn_left_10to11 score: 0.9975351 box: [ 216 1524  382 1646]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_095711.png t_inference_elapsed: 0.2244584560394287\n",
      "  Box: 0 class: turn_right_1to2 score: 0.99897826 box: [ 198 1546  362 1673]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_095723.png t_inference_elapsed: 0.22937679290771484\n",
      "  Box: 0 class: overpass_entrance_left score: 0.77892923 box: [ 228 1366  375 1532]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_095746.png t_inference_elapsed: 0.21467089653015137\n",
      "  Box: 0 class: right_urbanexpressway_entrance score: 0.59474206 box: [ 160 1362  326 1495]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_095752.png t_inference_elapsed: 0.22227692604064941\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_095758.png t_inference_elapsed: 0.21915435791015625\n",
      "  Box: 0 class: right_urbanexpressway_entrance score: 0.9840635 box: [ 196 1449  372 1648]\n",
      "  Box: 1 class: go_straight score: 0.59161603 box: [177 230 264 321]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_095922.png t_inference_elapsed: 0.2187645435333252\n",
      "  Box: 0 class: right_urbanexpressway_exit score: 0.89255637 box: [ 209 1433  363 1586]\n",
      "  Box: 1 class: right_urbanexpressway_entrance score: 0.76258844 box: [ 195 1421  364 1589]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_095928.png t_inference_elapsed: 0.22617578506469727\n",
      "  Box: 0 class: right_urbanexpressway_entrance score: 0.9797335 box: [ 276 1618  417 1783]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_095929.png t_inference_elapsed: 0.22120881080627441\n",
      "  Box: 0 class: right_urbanexpressway_entrance score: 0.9300382 box: [ 225 1466  379 1654]\n",
      "  Box: 1 class: right_urbanexpressway_exit score: 0.7574579 box: [ 226 1464  383 1653]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_095939.png t_inference_elapsed: 0.2340075969696045\n",
      "  Box: 0 class: right_urbanexpressway_exit score: 0.6501231 box: [ 249 1483  405 1689]\n",
      "  Box: 1 class: right_urbanexpressway_entrance score: 0.64814043 box: [ 248 1493  403 1678]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_095944.png t_inference_elapsed: 0.22940826416015625\n",
      "  Box: 0 class: go_straight score: 0.80705625 box: [ 284 1512  367 1591]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_095948.png t_inference_elapsed: 0.22794651985168457\n",
      "  Box: 0 class: speedlimit_60 score: 0.97796166 box: [348 436 450 582]\n",
      "  Box: 1 class: go_straight score: 0.91871846 box: [169 225 261 309]\n",
      "  Box: 2 class: speedlimit_60 score: 0.84018475 box: [183 458 255 620]\n",
      "  Box: 3 class: go_straight score: 0.6796089 box: [ 220 1482  304 1569]\n",
      "  Box: 4 class: go_straight score: 0.6199775 box: [ 209 1478  297 1617]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_100002.png t_inference_elapsed: 0.2261970043182373\n",
      "  Box: 0 class: go_straight score: 0.99817836 box: [ 230 1478  384 1577]\n",
      "  Box: 1 class: left_urbanexpressway_exit score: 0.56154424 box: [215 259 311 393]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_100013.png t_inference_elapsed: 0.22252607345581055\n",
      "  Box: 0 class: turn_right score: 0.98581207 box: [ 244 1456  403 1601]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181023_155924.png t_inference_elapsed: 0.22608423233032227\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181025_080939.png t_inference_elapsed: 0.22222566604614258\n",
      "  Box: 0 class: go_straight_expressway_entrance score: 0.75408363 box: [ 201 1382  346 1527]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/20181025_082452.png t_inference_elapsed: 0.22734832763671875\n",
      "  Box: 0 class: speedlimit_60 score: 0.9979558 box: [415 488 495 619]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/3.png t_inference_elapsed: 0.22261929512023926\n",
      "  Box: 0 class: turn_right score: 0.97584313 box: [ 535 1183  661 1305]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/4.png t_inference_elapsed: 0.22026991844177246\n",
      "Image: Test_ImageSet_datasetname/Val_tf/5.png t_inference_elapsed: 0.22488141059875488\n",
      "  Box: 0 class: turn_right score: 0.90289664 box: [ 527 1233  647 1361]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/6.png t_inference_elapsed: 0.2417457103729248\n",
      "  Box: 0 class: uturn score: 0.9935017 box: [  86 4304  324 4543]\n",
      "  Box: 1 class: turn_left_10to11 score: 0.9881095 box: [  54 3103  419 3412]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/60Km_Type02_05.png t_inference_elapsed: 0.5298976898193359\n",
      "  Box: 0 class: right_urbanexpressway_entrance score: 0.9996873 box: [ 14 472  79 555]\n",
      "  Box: 1 class: speedlimit_60 score: 0.9986644 box: [ 83  94 117 148]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/7.png t_inference_elapsed: 0.22542023658752441\n",
      "  Box: 0 class: speedlimit_60 score: 0.9997217 box: [196 308 246 394]\n",
      "  Box: 1 class: turn_left score: 0.99266547 box: [107 877 189 964]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/70Km_Tyoe02_05.png t_inference_elapsed: 0.21594715118408203\n",
      "  Box: 0 class: left_underpass_evasion score: 0.9990025 box: [ 22 470  76 547]\n",
      "  Box: 1 class: speedlimit_70 score: 0.9984072 box: [ 83  95 117 148]\n",
      "  Box: 2 class: uturn score: 0.9976476 box: [ 24 673  65 711]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/8.png t_inference_elapsed: 0.22107934951782227\n",
      "  Box: 0 class: turn_right_1to2 score: 0.9954426 box: [ 190 1884  387 2043]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/80Km_Tyoe01_05.png t_inference_elapsed: 0.22228431701660156\n",
      "  Box: 0 class: speedlimit_80 score: 0.99957854 box: [ 83  96 118 149]\n",
      "  Box: 1 class: turn_right_1to2 score: 0.9985669 box: [ 13 493  78 542]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/9.png t_inference_elapsed: 0.44644856452941895\n",
      "Image: Test_ImageSet_datasetname/Val_tf/datasetname_1.png t_inference_elapsed: 0.5330514907836914\n",
      "  Box: 0 class: turn_right_1to2 score: 0.9994511 box: [310 860 382 914]\n",
      "  Box: 1 class: left_urbanexpressway_exit score: 0.99899524 box: [ 313 1070  362 1124]\n",
      "  Box: 2 class: bus_lane score: 0.99877447 box: [345  83 397 135]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/datasetname_112.png t_inference_elapsed: 0.21955418586730957\n",
      "  Box: 0 class: go_straight score: 0.9985354 box: [307 868 389 912]\n",
      "  Box: 1 class: speedlimit_70 score: 0.9974329 box: [354  85 386 132]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/datasetname_1187.png t_inference_elapsed: 0.20889997482299805\n",
      "  Box: 0 class: rotary_right_1 score: 0.9725283 box: [313 853 382 920]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/datasetname_1201.png t_inference_elapsed: 0.21417641639709473\n",
      "  Box: 0 class: turn_left score: 0.99067163 box: [318 854 386 918]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/datasetname_1216.png t_inference_elapsed: 0.21111392974853516\n",
      "  Box: 0 class: turn_right score: 0.9980268 box: [319 853 384 922]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/datasetname_1217.png t_inference_elapsed: 0.21041107177734375\n",
      "  Box: 0 class: speedlimit_80 score: 0.99893206 box: [355  86 387 131]\n",
      "  Box: 1 class: turn_right score: 0.99226975 box: [317 854 383 924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: Test_ImageSet_datasetname/Val_tf/datasetname_122.png t_inference_elapsed: 0.21811914443969727\n",
      "  Box: 0 class: right_urbanexpressway_entrance score: 0.99693066 box: [310 849 386 930]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/datasetname_1259.png t_inference_elapsed: 0.21162128448486328\n",
      "  Box: 0 class: turn_right score: 0.9992925 box: [318 852 383 924]\n",
      "  Box: 1 class: speedlimit_60 score: 0.99872273 box: [353  86 387 131]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/datasetname_166.png t_inference_elapsed: 0.21401143074035645\n",
      "  Box: 0 class: right_urbanexpressway_entrance score: 0.9845813 box: [309 850 385 930]\n",
      "  Box: 1 class: speedlimit_90 score: 0.8874212 box: [356  84 387 130]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/datasetname_2893.png t_inference_elapsed: 0.2162632942199707\n",
      "Image: Test_ImageSet_datasetname/Val_tf/datasetname_2949.png t_inference_elapsed: 0.20908808708190918\n",
      "  Box: 0 class: turn_left score: 0.9968076 box: [318 855 384 918]\n",
      "  Box: 1 class: speedlimit_80 score: 0.85197943 box: [356  86 387 131]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/datasetname_4578.png t_inference_elapsed: 0.20959711074829102\n",
      "  Box: 0 class: go_straight score: 0.9989943 box: [307 867 386 911]\n",
      "  Box: 1 class: speedlimit_70 score: 0.9962979 box: [354  86 387 131]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/datasetname_5.png t_inference_elapsed: 0.2235279083251953\n",
      "  Box: 0 class: turn_right_1to2 score: 0.9989698 box: [310 861 382 914]\n",
      "  Box: 1 class: bus_lane score: 0.9987129 box: [348  84 398 134]\n",
      "  Box: 2 class: left_urbanexpressway_exit score: 0.99862254 box: [ 313 1070  362 1122]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/datasetname_533.png t_inference_elapsed: 0.21167683601379395\n",
      "  Box: 0 class: turn_right_1to2 score: 0.99927133 box: [312 860 382 914]\n",
      "  Box: 1 class: speedlimit_50 score: 0.99174213 box: [355  86 387 130]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/datasetname_57.png t_inference_elapsed: 0.21416783332824707\n",
      "  Box: 0 class: turn_right_1to2 score: 0.9989141 box: [314 859 383 916]\n",
      "  Box: 1 class: speedlimit_110 score: 0.9986499 box: [356  83 386 131]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/datasetname_70.png t_inference_elapsed: 0.20401740074157715\n",
      "  Box: 0 class: left_urbanexpressway_exit score: 0.9958335 box: [307 846 387 931]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/datasetname_77.png t_inference_elapsed: 0.2089691162109375\n",
      "Image: Test_ImageSet_datasetname/Val_tf/datasetname_80.png t_inference_elapsed: 0.21249127388000488\n",
      "  Box: 0 class: turn_right_1to2 score: 0.8096804 box: [316 860 387 914]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/datasetname_87.png t_inference_elapsed: 0.20144915580749512\n",
      "  Box: 0 class: right_urbanexpressway_exit score: 0.995516 box: [311 845 389 938]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/create_scr.png t_inference_elapsed: 0.40499353408813477\n",
      "  Box: 0 class: speedlimit_60 score: 0.9996277 box: [ 85  84 114 132]\n",
      "  Box: 1 class: turn_right score: 0.99863344 box: [ 43 865 107 927]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/highwayinout_14.png t_inference_elapsed: 0.5319263935089111\n",
      "  Box: 0 class: right_urbanexpressway_exit score: 0.99936 box: [ 64 601 146 707]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/lefttype_12.png t_inference_elapsed: 0.20641803741455078\n",
      "  Box: 0 class: turn_left score: 0.9989767 box: [ 85 619 160 694]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/ref_1.png t_inference_elapsed: 0.3083171844482422\n",
      "  Box: 0 class: left_underpass_evasion score: 0.67230827 box: [  28 1356  130 1483]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/ref_10.png t_inference_elapsed: 0.20495891571044922\n",
      "  Box: 0 class: overpass_entrance_left score: 0.92054325 box: [  27 1357  131 1464]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/ref_11.png t_inference_elapsed: 0.20066380500793457\n",
      "  Box: 0 class: speedlimit_60 score: 0.96902007 box: [112 147 164 218]\n",
      "  Box: 1 class: go_straight score: 0.57815254 box: [  50 1363  116 1433]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/ref_12.png t_inference_elapsed: 0.21036839485168457\n",
      "  Box: 0 class: right_urbanexpressway_exit score: 0.9679808 box: [  21 1348  132 1479]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/ref_13.png t_inference_elapsed: 0.204392671585083\n",
      "  Box: 0 class: turn_right score: 0.9968598 box: [  30 1372  130 1470]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/ref_14.png t_inference_elapsed: 0.205672025680542\n",
      "  Box: 0 class: rotary_right_4 score: 0.9761071 box: [  27 1364  129 1468]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/ref_15.png t_inference_elapsed: 0.1961498260498047\n",
      "  Box: 0 class: rotary_left_11 score: 0.9052506 box: [  20 1355  130 1470]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/ref_2.png t_inference_elapsed: 0.1947169303894043\n",
      "  Box: 0 class: turn_left_10to11 score: 0.9929351 box: [  23 1367  127 1455]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/ref_3.png t_inference_elapsed: 0.20814776420593262\n",
      "  Box: 0 class: turn_right score: 0.99860007 box: [  31 1371  128 1470]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/ref_4.png t_inference_elapsed: 0.20496106147766113\n",
      "  Box: 0 class: bus_lane score: 0.99738306 box: [103 150 178 223]\n",
      "  Box: 1 class: right_urbanexpressway_exit score: 0.9170286 box: [  23 1347  133 1488]\n",
      "  Box: 2 class: right_urbanexpressway_entrance score: 0.5867774 box: [  28 1354  126 1474]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/ref_5.png t_inference_elapsed: 0.2088637351989746\n",
      "  Box: 0 class: speedlimit_60 score: 0.9970696 box: [112 146 164 218]\n",
      "  Box: 1 class: left_underpass_evasion score: 0.6003544 box: [  33 1359  125 1485]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/ref_7.png t_inference_elapsed: 0.19917082786560059\n",
      "  Box: 0 class: speedlimit_60 score: 0.99928015 box: [116 150 162 219]\n",
      "  Box: 1 class: turn_left score: 0.9952362 box: [  27 1362  129 1459]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/ref_8.png t_inference_elapsed: 0.21082782745361328\n",
      "  Box: 0 class: left_urbanexpressway_exit score: 0.615944 box: [  25 1360  133 1478]\n",
      "  Box: 1 class: right_urbanexpressway_entrance score: 0.51071495 box: [  29 1355  129 1481]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/ref_9.png t_inference_elapsed: 0.2017958164215088\n",
      "  Box: 0 class: turn_left_10to11 score: 0.9831392 box: [  25 1369  130 1455]\n",
      "  Box: 1 class: go_straight score: 0.9156061 box: [  27 1723   71 1767]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/righttype_07.png t_inference_elapsed: 0.20998620986938477\n",
      "  Box: 0 class: turn_right score: 0.99924767 box: [ 88 628 158 703]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/speedlimit60_11.png t_inference_elapsed: 0.21578741073608398\n",
      "  Box: 0 class: speedlimit_60 score: 0.99938357 box: [156 127 199 194]\n",
      "  Box: 1 class: uturn score: 0.98004377 box: [ 73 621 151 694]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/speedlimit80_01.png t_inference_elapsed: 0.20650219917297363\n",
      "  Box: 0 class: speedlimit_80 score: 0.9995129 box: [151 122 194 191]\n",
      "  Box: 1 class: go_straight score: 0.9993943 box: [ 62 631 145 683]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/test.png t_inference_elapsed: 0.2569713592529297\n",
      "  Box: 0 class: left_underpass_evasion score: 0.7654477 box: [ 22 901  84 982]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/test_image_3.png t_inference_elapsed: 0.2172718048095703\n",
      "  Box: 0 class: turn_right_1to2 score: 0.998906 box: [320 878 396 940]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/test_image_48.png t_inference_elapsed: 0.19988656044006348\n",
      "  Box: 0 class: go_straight score: 0.99961346 box: [353 887 385 911]\n",
      "  Box: 1 class: speedlimit_80 score: 0.9992612 box: [376 127 410 166]\n",
      "Image: Test_ImageSet_datasetname/Val_tf/test_visualization.png t_inference_elapsed: 0.19922423362731934\n",
      "('mean t_elapsed', 2.9032201857506474, 'mean t_inference_elapsed', 0.23524663116358505)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import visualization_utils as vis_util\n",
    "\n",
    "\n",
    "im_names = TEST_IMAGE_PATHS\n",
    "\n",
    "\n",
    "t_start = time.time()\n",
    "t_inference_elapsed_sum = 0.0\n",
    "for image_path in im_names:\n",
    "    # the array based representation of the image will be used later in order to prepare the\n",
    "    # result image with boxes and labels on it.\n",
    "    #image_np = load_image_into_numpy_array(Image.open(image_path))\n",
    "    image_np = cv2.imread(image_path, flags=cv2.IMREAD_COLOR )\n",
    "    image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    # Run inference\n",
    "    t_inference_start = time.time()\n",
    "    output_dict = sess.run(tensor_dict,feed_dict={image_tensor_: image_np_expanded})\n",
    "    t_inference_elapsed = (time.time() - t_inference_start)\n",
    "    t_inference_elapsed_sum += t_inference_elapsed\n",
    "    \n",
    "    # textual report\n",
    "    detection_boxes = output_dict['detection_boxes'][0]\n",
    "    detection_classes = output_dict['detection_classes'][0].astype(int)\n",
    "    detection_scores = output_dict['detection_scores'][0]\n",
    "    \n",
    "    detection_masks = None\n",
    "    if output_dict.get('detection_masks'):\n",
    "        detection_masks, _ = output_dict.get('detection_masks')\n",
    "    \n",
    "    print('Image:',image_path,'t_inference_elapsed:',t_inference_elapsed)\n",
    "\n",
    "    image_size = image_np.shape[:2] * 2\n",
    "\n",
    "    true_boxes_index = np.where(detection_scores > 0.5)[0]\n",
    "    for i, box in enumerate(detection_boxes[true_boxes_index]):\n",
    "        print('  Box:',i,'class:',category_index[detection_classes[i]]['name'],\n",
    "              'score:',detection_scores[i],'box:',(box * image_size).astype(int))\n",
    "\n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        detection_boxes,\n",
    "        detection_classes,\n",
    "        detection_scores,\n",
    "        category_index,\n",
    "        instance_masks=detection_masks, # output_dict.get('detection_masks'),\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(image_np)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(image_cache_path(image_path))\n",
    "    plt.close()\n",
    "t_elapsed = time.time() - t_start\n",
    "t_elapsed /= len(im_names)\n",
    "t_inference_elapsed_sum /= len(im_names)\n",
    "print(('mean t_elapsed',t_elapsed,'mean t_inference_elapsed',t_inference_elapsed_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback import print_exc\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "\n",
    "def find_groundtruth(filepath):\n",
    "    filepath_base, _ = os.path.splitext(filepath)\n",
    "    dir_, base_ = os.path.split(filepath_base)\n",
    "    try:\n",
    "        gt_image_path = glob.glob('Test_ImageSet_datasetname/Val_tf/' + base_ + '.*')[0]\n",
    "        gt_anno_path  = glob.glob('annotations/xmls/Val/' + base_ + '.xml')[0]\n",
    "        return gt_image_path, gt_anno_path\n",
    "    except:\n",
    "        print(('gt not found for',filepath),file=sys.stderr)\n",
    "        return None, None\n",
    "\n",
    "class AnnotationNode:\n",
    "    def update(self,**kwargs):\n",
    "        vars(self).update(dict(**kwargs))\n",
    "    def __repr__(self):\n",
    "        return str(vars(self))\n",
    "\n",
    "def parse_annotation(filename,image_dir=None,check_image=False):\n",
    "    anno_ = ET.parse(filename).getroot()\n",
    "    image_filename = anno_.findtext('image_filename')\n",
    "    image_path = anno_.findtext('path')\n",
    "\n",
    "    if image_dir is not None:\n",
    "        dir_, file_ = os.path.split(image_path)\n",
    "        image_path = os.path.join(image_dir,file_)\n",
    "\n",
    "    if check_image:\n",
    "        try:\n",
    "            img = Image.open(image_path)\n",
    "            del img\n",
    "        except:\n",
    "            print(('parse_annotation','image load failed',filename,image_path),file=sys.stderr)\n",
    "            return None\n",
    "\n",
    "    segmented = int(anno_.findtext('segmented'))\n",
    "    objects = []\n",
    "    for obj_ in anno_.findall('object'):\n",
    "        obj_name = obj_.findtext('name')\n",
    "        obj_pose = obj_.findtext('pose')\n",
    "        obj_truncated = int(obj_.findtext('truncated'))\n",
    "        obj_difficult = int(obj_.findtext('difficult'))\n",
    "        obj_bndbox = [[\n",
    "            int(obj_.find('bndbox').findtext('xmin')),\n",
    "            int(obj_.find('bndbox').findtext('ymin')),\n",
    "        ],[\n",
    "            int(obj_.find('bndbox').findtext('xmax')),\n",
    "            int(obj_.find('bndbox').findtext('ymax')),\n",
    "        ]]\n",
    "        obj = AnnotationNode()\n",
    "        obj.update(\n",
    "            name=obj_name,\n",
    "            pose=obj_pose,\n",
    "            truncated=obj_truncated,\n",
    "            difficult=obj_difficult,\n",
    "            bndbox=obj_bndbox,\n",
    "        )\n",
    "        objects.append(obj)\n",
    "    anno = AnnotationNode()\n",
    "    anno.update(\n",
    "        anno_path=filename,\n",
    "        image_path=image_path,\n",
    "        segmented=segmented,\n",
    "        objects=objects,\n",
    "    )\n",
    "    return anno\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def show_annotation(anno_,image_=None,ax=None):\n",
    "    if image_ is None:\n",
    "        image_ = anno_.image_path\n",
    "\n",
    "    try:\n",
    "        img = Image.open(image_)\n",
    "    except:\n",
    "        print_exc()\n",
    "        print('*** Image read error:',image_,file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        _, ax_ = plt.subplots(1,figsize=(11,11))\n",
    "    else:\n",
    "        ax_ = ax\n",
    "\n",
    "    ax_.imshow(img)\n",
    "\n",
    "    for obj in anno_.objects:\n",
    "        min_, max_ = obj.bndbox\n",
    "        minx, miny = min_\n",
    "        maxx, maxy = max_\n",
    "        ax_.add_patch(plt.Rectangle(min_,maxx-minx,maxy-miny,fill=False,color='r',lw=3))\n",
    "        ax_.text(minx, miny - 15, obj.name,color='r',fontsize=12,bbox=dict(facecolor='blue',alpha=0.5))\n",
    "    ax_.set_title('{:s}, {:d} objs'.format(os.path.basename(anno_.image_path),len(anno_.objects)))\n",
    "    if ax is None:\n",
    "        plt.tight_layout()\n",
    "        plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c7bed96f3444b30a3018aed32ed8d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='num', max=78), Output()), _dom_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact,IntSlider\n",
    "# from IPython.display import Image\n",
    "\n",
    "@interact(num=IntSlider(0,0,len(im_names)-1,continuous_update=False))\n",
    "def show_result(num):\n",
    "    im_name = im_names[num]\n",
    "    gt_image_path, gt_anno_path = find_groundtruth(im_name)\n",
    "    if gt_image_path is not None:\n",
    "        plt.figure(figsize=(11,6))\n",
    "        ax = plt.subplot(121)\n",
    "        result_image_path = image_cache_path(im_name)\n",
    "        ax.imshow(Image.open(result_image_path))\n",
    "        ax.set_title(result_image_path)\n",
    "        ax.set_axis_off()\n",
    "        ax = plt.subplot(122)\n",
    "        anno = parse_annotation(gt_anno_path)\n",
    "        show_annotation(anno, gt_image_path, ax=ax)\n",
    "        ax.set_axis_off()\n",
    "        plt.tight_layout()\n",
    "        plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
